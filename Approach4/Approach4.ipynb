{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all modules here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.linear_model as sk\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"/home/shinigami/new/LabelNoise/haberman.data\",header=None)\n",
    "# data.fillna(data.median(),inplace=True)\n",
    "# data.columns = ['Age','Year','Nodes','Survival_status']\n",
    "# data['Survival_status'] = data['Survival_status'].astype(int)\n",
    "# data['Survival_status'] = data['Survival_status'].map({2:0 , 1:1})\n",
    "# data.drop_duplicates(inplace=True)\n",
    "# label_col_name = 'Survival_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/home/shinigami/new/LabelNoise/SPECT.train',header=None)\n",
    "# # features = df.loc[:,df.columns!=0]\n",
    "# # label = df[0]\n",
    "# label_col_name = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/home/shinigami/new/LabelNoise/heart-disease.data',header=None, names=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','label'])\n",
    "# label = df['label']\n",
    "# df.replace(r'?',np.nan,inplace=True)\n",
    "# df.fillna(df.median(),inplace=True)\n",
    "# df_std = StandardScaler().fit_transform(df)\n",
    "# df = pd.DataFrame(df_std)\n",
    "# df.head()\n",
    "# df.columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','label']\n",
    "# df['label'] = label\n",
    "# df['label'] = df['label'].map({1:1,2:1,3:1,4:1,0:0})\n",
    "# data=df\n",
    "# label_col_name = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"/home/shinigami/new/LabelNoise/Binary Classified Datasets/ionosphere.csv\")\n",
    "# data.head(4)\n",
    "# # data.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "# label_col_name = 'g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    762\n",
       "1    610\n",
       "Name: 4, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/shinigami/new/LabelNoise/Binary Classified Datasets/data_banknote_authentication.txt\",header=None)\n",
    "data.head(3)\n",
    "label_col_name=4\n",
    "data[4].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach4(data,label_col_name,p):\n",
    "    #################################################################################\n",
    "    data['Original_label'] = data[label_col_name]\n",
    "    class0 = data.loc[data[label_col_name]!=1,:]\n",
    "    class1 = data.loc[data[label_col_name]!=0,:]\n",
    "    def add_noise(data,p):\n",
    "        sample = data.sample(frac=p)\n",
    "        for i in list(sample.index):\n",
    "            data[label_col_name][i] = int(not data[label_col_name][i])\n",
    "    add_noise(class0,p)\n",
    "    add_noise(class1,p)\n",
    "    data_df = pd.concat([class0,class1])\n",
    "    data_df.reset_index(inplace=True,drop=True)\n",
    "#     print(data_df.head(3))\n",
    "    noisy_indices = data_df[data_df[label_col_name]!=data_df['Original_label']].index\n",
    "    #################################################################################\n",
    "    #ENSEMBLE\n",
    "    features = data_df[data_df.columns.difference([label_col_name,'Original_label'])]\n",
    "    label = data_df[label_col_name]\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(features,label,test_size=0.38)\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(xtrain,ytrain)\n",
    "    predicted = defaultdict(list)\n",
    "    predict = lr.predict(features)\n",
    "    for i in range(len(data)):\n",
    "        predicted[i].append(predict[i])\n",
    "    \n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(xtrain,ytrain)\n",
    "    predict = dt.predict(features)\n",
    "    for i in range(len(data)):\n",
    "        predicted[i].append(predict[i])\n",
    "        \n",
    "    nb = GaussianNB()\n",
    "    nb.fit(xtrain,ytrain)\n",
    "    predict = nb.predict(features)\n",
    "    for i in range(len(data)):\n",
    "        predicted[i].append(predict[i])\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(xtrain,ytrain)\n",
    "    predict = rf.predict(features)\n",
    "    for i in range(len(data)):\n",
    "        predicted[i].append(predict[i])\n",
    "        \n",
    "    unlabel = {}\n",
    "    for row in predicted:\n",
    "        if sum(predicted[row])>3:\n",
    "            unlabel[row] = 1\n",
    "        elif sum(predicted[row]) == 0:\n",
    "            unlabel[row] = 0\n",
    "        else:\n",
    "            unlabel[row] = random.choice([1,0])\n",
    "    unlabel = pd.DataFrame(list(unlabel.items()))\n",
    "    unlabel.set_index(0,inplace=True)\n",
    "    unlabel.columns = ['unlabeled']\n",
    "    data_df = data_df.join(unlabel)\n",
    "    \n",
    "    \n",
    "    #################################################################################\n",
    "    p2p = 0\n",
    "    p2n = 0\n",
    "    n2p = 0\n",
    "    n2n = 0\n",
    "    for i in list(data_df.index):\n",
    "        if data_df[label_col_name][i]!=data_df['unlabeled'][i]:\n",
    "            if i in noisy_indices:\n",
    "                n2n += 1\n",
    "            else:\n",
    "                p2n += 1\n",
    "        else:\n",
    "            if i in noisy_indices:\n",
    "                n2p += 1\n",
    "            else:\n",
    "                p2p += 1\n",
    "    return pd.DataFrame(data={'n2n':[n2n],'p2n':[p2n],'n2p':[n2p],'p2p':[p2p]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n2n  p2n  n2p   p2p\n",
      "0   81  154   56  1081\n",
      "   n2n  p2n  n2p  p2p\n",
      "0  156  159  118  939\n",
      "   n2n  p2n  n2p  p2p\n",
      "0  250  163  162  797\n",
      "   n2n  p2n  n2p  p2p\n",
      "0  311  149  238  674\n",
      "   n2n  p2n  n2p  p2p\n",
      "0  255  272  431  414\n"
     ]
    }
   ],
   "source": [
    "print(approach4(data,label_col_name,0.1))\n",
    "print(approach4(data,label_col_name,0.2))\n",
    "print(approach4(data,label_col_name,0.3))\n",
    "print(approach4(data,label_col_name,0.4))\n",
    "print(approach4(data,label_col_name,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
