{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[313]:\n",
    "\n",
    "\n",
    "#import all modules here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.linear_model as sk\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Approach3(data_df,label_column, N, noise_frac):\n",
    "\n",
    "    def add_noise(data, col):\n",
    "        class0 = data.loc[data[col]!=1,:]\n",
    "        class1 = data.loc[data[col]!=0,:]\n",
    "        def noise(data):\n",
    "            sample = data.sample(frac = noise_frac)\n",
    "            for i in list(sample.index):\n",
    "                data[col][i] = int(not data[col][i])\n",
    "            return list(sample.index)    \n",
    "        noise0 = noise(class0)\n",
    "        noise1 = noise(class1)\n",
    "        noisy_indices = noise0+noise1\n",
    "        mislabeled = pd.concat([class0,class1])\n",
    "        indices = list(mislabeled.index)\n",
    "        return mislabeled,noisy_indices\n",
    "\n",
    "\n",
    "    # In[317]:\n",
    "\n",
    "\n",
    "    mislabeled,noisy_indices = add_noise(data_df, label_column)\n",
    "\n",
    "\n",
    "    # In[318]:\n",
    "\n",
    "\n",
    "    def distance_from_centroid(df,centroids,data_label):\n",
    "        d = defaultdict(list)\n",
    "        for index in df.index:\n",
    "            dist = 0\n",
    "            for i in range(len(centroids[0])):\n",
    "                dist+=(centroids[df.loc[index,'cluster']][i] - df.loc[index,df.columns[i]])**2\n",
    "            d[df.loc[index,'cluster']].append([dist,index,data_label[index]])\n",
    "        return d\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # In[319]:\n",
    "\n",
    "\n",
    "    def ratio_in_cluster(features,data_label,n):\n",
    "        majority_label_in_cluster = defaultdict(None)\n",
    "        km = KMeans(n_clusters = n)\n",
    "        km.fit(features)\n",
    "        label = km.labels_\n",
    "        print(len(label))\n",
    "        print(features.shape)\n",
    "        features['cluster'] = label\n",
    "\n",
    "        distance = distance_from_centroid(features,km.cluster_centers_,data_label)\n",
    "\n",
    "        for i in distance.keys():\n",
    "            distance[i] = sorted(distance[i],key=lambda x: x[0])\n",
    "\n",
    "        normalized_distance = dict(distance)\n",
    "        label_ratio_count = {}\n",
    "\n",
    "        for i in normalized_distance:\n",
    "            temp = [0,0]\n",
    "            for j in range(len(normalized_distance[i])):\n",
    "                normalized_distance[i][j][0] = normalized_distance[i][j][0]/normalized_distance[i][-1][0]\n",
    "                temp[normalized_distance[i][j][-1]] +=1\n",
    "\n",
    "            temp[0],temp[1] = temp[0]/sum(temp),temp[1]/sum(temp)\n",
    "            label_ratio_count[i] = temp\n",
    "\n",
    "            if temp[0] > temp[1] and temp[0]>=0.7:\n",
    "                majority_label_in_cluster[i] = 0\n",
    "            elif temp[0] < temp[1] and temp[1]>=0.7:\n",
    "                majority_label_in_cluster[i] = 1\n",
    "            else:\n",
    "                majority_label_in_cluster[i] = None\n",
    "\n",
    "        return(normalized_distance, majority_label_in_cluster)\n",
    "        #return pd.DataFrame(data=label_ratio_count),majority_label_in_cluster  \n",
    "\n",
    "\n",
    "\n",
    "    # In[320]:\n",
    "\n",
    "\n",
    "    normalized_distance, majority_label_in_cluster = ratio_in_cluster(mislabeled.loc[:,mislabeled.columns!=label_column],mislabeled[label_column],N)\n",
    "\n",
    "\n",
    "    # In[321]:\n",
    "\n",
    "\n",
    "    points_removed = []\n",
    "    reduced_points = defaultdict(list)\n",
    "    for cluster_id in normalized_distance.keys():\n",
    "        count = 0\n",
    "        for point in normalized_distance[cluster_id]:\n",
    "            if count/len(normalized_distance[cluster_id]) > 0.75:\n",
    "                if point[-1] != majority_label_in_cluster[cluster_id] and majority_label_in_cluster[cluster_id]!=None:\n",
    "                    points_removed.append(point)\n",
    "                    continue\n",
    "                else:\n",
    "                    reduced_points[cluster_id].append(point)\n",
    "                    count+=1\n",
    "            else:\n",
    "                reduced_points[cluster_id].append(point)\n",
    "                count +=1\n",
    "\n",
    "\n",
    "    # In[322]:\n",
    "\n",
    "\n",
    "    # result = []\n",
    "    # for cluster_id in normalized_distance:\n",
    "    #     print(len(normalized_distance[cluster_id]), len(reduced_points[cluster_id]))\n",
    "    #     print((len(reduced_points[cluster_id]) * 1.0) -  len(normalized_distance[cluster_id]))\n",
    "    #     print()\n",
    "\n",
    "\n",
    "    # In[323]:\n",
    "\n",
    "\n",
    "    #reduced_points\n",
    "\n",
    "\n",
    "    # In[324]:\n",
    "\n",
    "\n",
    "    #majority_label_in_cluster\n",
    "\n",
    "\n",
    "    # In[325]:\n",
    "\n",
    "\n",
    "    #points_removed\n",
    "\n",
    "\n",
    "    # In[326]:\n",
    "\n",
    "\n",
    "    noisy_indices = set(noisy_indices)\n",
    "    n_n = 0\n",
    "    p_n = 0\n",
    "    for point in points_removed:\n",
    "        if point[2] in noisy_indices:\n",
    "            n_n+=1\n",
    "        else:\n",
    "            p_n+=1\n",
    "    p_p = (len(mislabeled) - len(noisy_indices)) - p_n\n",
    "    n_p = len(noisy_indices) - n_n\n",
    "    print(\"# Observation in Culprit\",len(points_removed))\n",
    "    print(\"Noise to Noise\",n_n)\n",
    "    print(\"Pure to Noise\",p_n)\n",
    "    print(\"Noise to Pure\",n_p)\n",
    "    print(\"Pure to Pure\",p_p)\n",
    "    print('Pure %',100 * p_p/(len(mislabeled)-len(points_removed)))\n",
    "    print('Noisy %',100 * n_p/(len(mislabeled)-len(points_removed)))\n",
    "    print('Cleaned %',100 * n_n/(len(noisy_indices)))\n",
    "\n",
    "\n",
    "    # # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 14\n",
    "# data_df = pd.read_csv(\"../haberman.data\",header=None)\n",
    "# data_df.fillna(data_df.median(),inplace=True)\n",
    "# data_df.columns = ['Age','Year','Nodes','Survival_status']\n",
    "# data_df['Survival_status'] = data_df['Survival_status'].astype(int)\n",
    "# data_df['Survival_status'] = data_df['Survival_status'].map({2:0 , 1:1})\n",
    "# label_column = 'Survival_status'\n",
    "# noise_frac = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 14\n",
    "# data_df = pd.read_csv('../SPECT.train',header=None)\n",
    "# label_column = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../Binary Classified Datasets/ionosphere.csv')\n",
    "label_column = 'g'\n",
    "N = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "350\n",
      "(350, 34)\n",
      "# Observation in Culprit 24\n",
      "Noise to Noise 0\n",
      "Pure to Noise 24\n",
      "Noise to Pure 35\n",
      "Pure to Pure 291\n",
      "Pure % 89.2638036809816\n",
      "Noisy % 10.736196319018404\n",
      "Cleaned % 0.0\n",
      "\n",
      "0.2\n",
      "350\n",
      "(350, 34)\n",
      "# Observation in Culprit 24\n",
      "Noise to Noise 0\n",
      "Pure to Noise 24\n",
      "Noise to Pure 70\n",
      "Pure to Pure 256\n",
      "Pure % 78.52760736196319\n",
      "Noisy % 21.47239263803681\n",
      "Cleaned % 0.0\n",
      "\n",
      "0.3\n",
      "350\n",
      "(350, 34)\n",
      "# Observation in Culprit 0\n",
      "Noise to Noise 0\n",
      "Pure to Noise 0\n",
      "Noise to Pure 105\n",
      "Pure to Pure 245\n",
      "Pure % 70.0\n",
      "Noisy % 30.0\n",
      "Cleaned % 0.0\n",
      "\n",
      "0.4\n",
      "350\n",
      "(350, 34)\n",
      "# Observation in Culprit 0\n",
      "Noise to Noise 0\n",
      "Pure to Noise 0\n",
      "Noise to Pure 140\n",
      "Pure to Pure 210\n",
      "Pure % 60.0\n",
      "Noisy % 40.0\n",
      "Cleaned % 0.0\n",
      "\n",
      "0.5\n",
      "350\n",
      "(350, 34)\n",
      "# Observation in Culprit 0\n",
      "Noise to Noise 0\n",
      "Pure to Noise 0\n",
      "Noise to Pure 175\n",
      "Pure to Pure 175\n",
      "Pure % 50.0\n",
      "Noisy % 50.0\n",
      "Cleaned % 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    print(i/10)\n",
    "    Approach3(data_df,label_column,N,i/10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    }
   ],
   "source": [
    "print(len(data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X0</th>\n",
       "      <th>X0.99539</th>\n",
       "      <th>X.0.05889</th>\n",
       "      <th>X0.85243</th>\n",
       "      <th>X0.02306</th>\n",
       "      <th>X0.83398</th>\n",
       "      <th>X.0.37708</th>\n",
       "      <th>X1.1</th>\n",
       "      <th>X0.03760</th>\n",
       "      <th>...</th>\n",
       "      <th>X.0.51171</th>\n",
       "      <th>X0.41078</th>\n",
       "      <th>X.0.46168</th>\n",
       "      <th>X0.21266</th>\n",
       "      <th>X.0.34090</th>\n",
       "      <th>X0.42267</th>\n",
       "      <th>X.0.54487</th>\n",
       "      <th>X0.18641</th>\n",
       "      <th>X.0.45300</th>\n",
       "      <th>g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02337</td>\n",
       "      <td>-0.00592</td>\n",
       "      <td>-0.09924</td>\n",
       "      <td>-0.11949</td>\n",
       "      <td>-0.00763</td>\n",
       "      <td>-0.11824</td>\n",
       "      <td>0.14706</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01535</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.09223</td>\n",
       "      <td>-0.07859</td>\n",
       "      <td>0.00732</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00039</td>\n",
       "      <td>0.12011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X0  X0.99539  X.0.05889  X0.85243  X0.02306  X0.83398  X.0.37708  \\\n",
       "0   1   0   1.00000   -0.18829   0.93035  -0.36156  -0.10868   -0.93597   \n",
       "1   1   0   1.00000   -0.03365   1.00000   0.00485   1.00000   -0.12062   \n",
       "2   1   0   1.00000   -0.45161   1.00000   1.00000   0.71216   -1.00000   \n",
       "3   1   0   1.00000   -0.02401   0.94140   0.06531   0.92106   -0.23255   \n",
       "4   1   0   0.02337   -0.00592  -0.09924  -0.11949  -0.00763   -0.11824   \n",
       "\n",
       "      X1.1  X0.03760 ...  X.0.51171  X0.41078  X.0.46168  X0.21266  X.0.34090  \\\n",
       "0  1.00000  -0.04549 ...   -0.26569  -0.20468   -0.18401  -0.19040   -0.11593   \n",
       "1  0.88965   0.01198 ...   -0.40220   0.58984   -0.22145   0.43100   -0.17365   \n",
       "2  0.00000   0.00000 ...    0.90695   0.51613    1.00000   1.00000   -0.20099   \n",
       "3  0.77152  -0.16399 ...   -0.65158   0.13290   -0.53206   0.02431   -0.62197   \n",
       "4  0.14706   0.06637 ...   -0.01535  -0.03240    0.09223  -0.07859    0.00732   \n",
       "\n",
       "   X0.42267  X.0.54487  X0.18641  X.0.45300  g  \n",
       "0  -0.16626   -0.06288  -0.13738   -0.02447  0  \n",
       "1   0.60436   -0.24180   0.56045   -0.38238  1  \n",
       "2   0.25682    1.00000  -0.32382    1.00000  0  \n",
       "3  -0.05707   -0.59573  -0.04608   -0.65697  1  \n",
       "4   0.00000    0.00000  -0.00039    0.12011  0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
