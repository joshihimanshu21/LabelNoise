{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all modules here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.linear_model as sk\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"/home/shinigami/new/LabelNoise/haberman.data\",header=None)\n",
    "# data.fillna(data.median(),inplace=True)\n",
    "# data.columns = ['Age','Year','Nodes','Survival_status']\n",
    "# data['Survival_status'] = data['Survival_status'].astype(int)\n",
    "# data['Survival_status'] = data['Survival_status'].map({2:0 , 1:1})\n",
    "# data.drop_duplicates(inplace=True)\n",
    "# label_col_name = 'Survival_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/home/shinigami/new/LabelNoise/SPECT.train',header=None)\n",
    "# # features = df.loc[:,df.columns!=0]\n",
    "# # label = df[0]\n",
    "# label_col_name = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/home/shinigami/new/LabelNoise/heart-disease.data',header=None, names=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','label'])\n",
    "# label = df['label']\n",
    "# df.replace(r'?',np.nan,inplace=True)\n",
    "# df.fillna(df.median(),inplace=True)\n",
    "# df_std = StandardScaler().fit_transform(df)\n",
    "# df = pd.DataFrame(df_std)\n",
    "# df.head()\n",
    "# df.columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','label']\n",
    "# df['label'] = label\n",
    "# df['label'] = df['label'].map({1:1,2:1,3:1,4:1,0:0})\n",
    "# data=df\n",
    "# label_col_name = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"/home/shinigami/new/LabelNoise/Binary Classified Datasets/ionosphere.csv\")\n",
    "# data.head(4)\n",
    "# data.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "# label_col_name = 'g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    762\n",
       "1    610\n",
       "Name: 4, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/shinigami/new/LabelNoise/Binary Classified Datasets/data_banknote_authentication.txt\",header=None)\n",
    "data.head(3)\n",
    "label_col_name=4\n",
    "data[4].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_as_a_feature(data,label_col_name,p,noc,model):\n",
    "    ############################################\n",
    "    data['Original_label'] = data[label_col_name]\n",
    "    class0 = data.loc[data[label_col_name]!=1,:]\n",
    "    class1 = data.loc[data[label_col_name]!=0,:]\n",
    "    def add_noise(data,p):\n",
    "        sample = data.sample(frac=p)\n",
    "        for i in list(sample.index):\n",
    "            data[label_col_name][i] = int(not data[label_col_name][i])\n",
    "    add_noise(class0,p)\n",
    "    add_noise(class1,p)\n",
    "    data_df = pd.concat([class0,class1])\n",
    "    data_df.reset_index(inplace=True,drop=True)\n",
    "#     print(data_df.head(3))\n",
    "    noisy_indices = data_df[data_df[label_col_name]!=data_df['Original_label']].index\n",
    "#     print(list(noisy_indices))\n",
    "#     ############################################\n",
    "    km = KMeans(n_clusters=noc)\n",
    "    features = data_df[data_df.columns.difference([label_col_name,'Original_label'])]\n",
    "    label = data_df[label_col_name]\n",
    "    km.fit(features)\n",
    "    cluster_label = pd.Series(km.labels_)\n",
    "    data_df['Cluster'] = cluster_label\n",
    "    data_df = pd.get_dummies(data_df,columns=['Cluster'])\n",
    "    features = data_df[data_df.columns.difference([label_col_name,'Original_label'])]\n",
    "    label = data_df[label_col_name]\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(features,label,test_size=0.38)\n",
    "    m = model()\n",
    "    m.fit(xtrain,ytrain)\n",
    "    predict = m.predict(features)\n",
    "    p2p = 0\n",
    "    p2n = 0\n",
    "    n2p = 0\n",
    "    n2n = 0\n",
    "    for i in list(data_df.index):\n",
    "        if data_df[label_col_name][i]!=predict[i]:\n",
    "            if i in noisy_indices:\n",
    "                n2n += 1\n",
    "            else:\n",
    "                p2n += 1\n",
    "        else:\n",
    "            if i in noisy_indices:\n",
    "                n2p += 1\n",
    "            else:\n",
    "                p2p += 1\n",
    "    return pd.DataFrame(data={'n2n':[n2n],'p2n':[p2n],'n2p':[n2p],'p2p':[p2p]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "models = [SVC,RandomForestClassifier,GaussianNB,LogisticRegression,DecisionTreeClassifier]\n",
    "#result = pd.DataFrame(data={'Total Noise':[], 'Total Detected labels':[], 'True Identified labels':[], 'False identified labels':[], 'Total Noise Ratio':[], 'True Identified Ratio':[]})\n",
    "result = pd.DataFrame()\n",
    "for model in models:\n",
    "    temp = cluster_as_a_feature(data,label_col_name,0.1,14,model)\n",
    "    result = result.append(temp, ignore_index=True)\n",
    "result['Model']=pd.Series([\"SVC\",\"Random Forest\",\"Naive Bayes\",\"Logistic Regression\",\"Decision Tree\"])\n",
    "l.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SVC,RandomForestClassifier,GaussianNB,LogisticRegression,DecisionTreeClassifier]\n",
    "#result = pd.DataFrame(data={'Total Noise':[], 'Total Detected labels':[], 'True Identified labels':[], 'False identified labels':[], 'Total Noise Ratio':[], 'True Identified Ratio':[]})\n",
    "result = pd.DataFrame()\n",
    "for model in models:\n",
    "    temp = cluster_as_a_feature(data,label_col_name,0.2,14,model)\n",
    "    result = result.append(temp, ignore_index=True)\n",
    "result['Model']=pd.Series([\"SVC\",\"Random Forest\",\"Naive Bayes\",\"Logistic Regression\",\"Decision Tree\"])\n",
    "l.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SVC,RandomForestClassifier,GaussianNB,LogisticRegression,DecisionTreeClassifier]\n",
    "#result = pd.DataFrame(data={'Total Noise':[], 'Total Detected labels':[], 'True Identified labels':[], 'False identified labels':[], 'Total Noise Ratio':[], 'True Identified Ratio':[]})\n",
    "result = pd.DataFrame()\n",
    "for model in models:\n",
    "    temp = cluster_as_a_feature(data,label_col_name,0.3,14,model)\n",
    "    result = result.append(temp, ignore_index=True)\n",
    "result['Model']=pd.Series([\"SVC\",\"Random Forest\",\"Naive Bayes\",\"Logistic Regression\",\"Decision Tree\"])\n",
    "l.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SVC,RandomForestClassifier,GaussianNB,LogisticRegression,DecisionTreeClassifier]\n",
    "#result = pd.DataFrame(data={'Total Noise':[], 'Total Detected labels':[], 'True Identified labels':[], 'False identified labels':[], 'Total Noise Ratio':[], 'True Identified Ratio':[]})\n",
    "result = pd.DataFrame()\n",
    "for model in models:\n",
    "    temp = cluster_as_a_feature(data,label_col_name,0.4,14,model)\n",
    "    result = result.append(temp, ignore_index=True)\n",
    "result['Model']=pd.Series([\"SVC\",\"Random Forest\",\"Naive Bayes\",\"Logistic Regression\",\"Decision Tree\"])\n",
    "l.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SVC,RandomForestClassifier,GaussianNB,LogisticRegression,DecisionTreeClassifier]\n",
    "#result = pd.DataFrame(data={'Total Noise':[], 'Total Detected labels':[], 'True Identified labels':[], 'False identified labels':[], 'Total Noise Ratio':[], 'True Identified Ratio':[]})\n",
    "result = pd.DataFrame()\n",
    "for model in models:\n",
    "    temp = cluster_as_a_feature(data,label_col_name,0.5,14,model)\n",
    "    result = result.append(temp, ignore_index=True)\n",
    "result['Model']=pd.Series([\"SVC\",\"Random Forest\",\"Naive Bayes\",\"Logistic Regression\",\"Decision Tree\"])\n",
    "l.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.concat(l)).to_csv(\"cluster_as_a_feature_banknote.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
